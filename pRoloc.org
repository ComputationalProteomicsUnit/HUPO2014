#+TITLE: A state-of-the-art machine learning pipeline for the analysis of spatial proteomics data
#+OPTIONS: toc:nil
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../css/style0.css" />

[[http://cpu.sysbiol.cam.ac.uk][Laurent Gatto]][1][2], Lisa M. Breckels[1][2], Thomas Naake[1][2], Samuel Wieczorek[3], Thomas Burger[3] and Kathryn S. Lilley[2]

[1] [[http://cpu.sysbiol.cam.ac.uk][Computational Proteomics Unit]], Department of Biochemistry, University of Cambridge, Cambridge, UK
[2] [[http://proteomics.bio.cam.ac.uk][Cambridge Centre for Proteomics]], Department of Biochemistry, University of Cambridge, Cambridge, UK
[3] Universite Grenoble-Alpes, CEA (iRSTV/BGE), INSERM (U1038), CNRS (FR3425), 38054 Grenoble, France

* Introduction and objectives 

Organelle proteomics, or spatial proteomics, is the systematic study
of protein sub-cellular localisation. Here, we focus on high-throughput
quantitative mass spectrometry-based techniques such as LOPIT and PCP
and demonstrate a robust and sound analysis pipeline using
state-of-the-art and novel machine learning algorithms implemented in
the pRoloc[4][5] R/Bioconductor package.

* Methods

We illustrate the pipeline using relevant real-world data sets
available from the pRolocdata package[4], documenting importing data
available in spreadsheet formats into the R environment, missing data
imputation, data quality control, facilitated organelle marker
assignment, protein clustering, identification of new, non-labelled
organelles using semi-supervised machine learning[6], protein
classification and data visualisation.

* Results and Discussion

While the pipeline automates some fundamental requirements such as
parameter optimisation via cross-validation, imputation of missing
values, organelle markers definition and allows the user to assess
such crucial parameters, we also highlight the importance of informed
user decisions and validation. Despite the requirement for elaborate
and cross-disciplinary tool sets, the biologists must remain in
control of the fate of their data and in a position to make informed
decisions about the data analysis and validity of the results to
produce biologically relevant and meaningful interpretation.

* Conclusions

Complex high dimensional data analysis is a challenging task. While
statistics and computer science provide the wider research community
with several algorithms and best practice, their application is often
difficult and may at times, when underlying assumptions are not met, lead
to misleading claims. We show how such state-of-the-art methods can be
applied on well-defined and annotated data in a coherent, traceable
and reproducible pipeline.


* Resources

- *software* [[http://is.gd/pRoloc]]
- *documentation* [[http://is.gd/pRoloc_tutorial]]
- *GUI* [[http://is.gd/pRolocGUI]]
- *data* [[http://is.gd/pRolocdata]]
- *Videos* [[http://is.gd/R4ProteomicsVideos]]
- *Poster* 

[4] [[http://bioinformatics.oxfordjournals.org/content/30/9/1322][Gatto L . /et al./ Bioinformatics. 2014 1;30(9):1322-4.]]
[5] [[http://www.mcponline.org./content/early/2014/05/20/mcp.M113.036350.abstract][Gatto L. /et al./ MCP 2014 Aug;13(8):1937-52.]]
[6] [[http://www.sciencedirect.com/science/article/pii/S1874391913000948][Breckels LM. /et al./ J Proteomics. 2013, 2(88), 129-40.]]

